# 摘要

# 方法
![](35.png)
整个压缩管线由两部分组成：特征金字塔+MLP
特征金字塔类似于NGP[[Instant Neural Graphics Primitives with a Multiresolution Hash Encoding]]，将特征信息保存到格点上，在取用时进行插值得到输入特征，MLP作为一个Decoder，用来解码最终的结果。
## 特征金字塔
纹理压缩后的结果是一个特征金字塔纹理$F_j$，考虑到mipmap，特征金字塔有多层，每一层由两个网格$G_0^j,G_1^j$组成，格点保存潜在向量值。设计如下：$G_0$是一个高分辨率网格，表征高频特征。而$G_1$是一个低分辨率网格，表征低频特征。
值得注意的是，每一层的特征金字塔可以对应多层mipmap，例如$F^0$可以对应mipmap的0,1,2,3层。而特征金字塔本身也类似一个mipmap高层分辨率为最底层的$(\frac{1}{2})^j$

实际中，使用的纹理分辨率如下：
![](12.png)

在实际的使用中，会对特征金字塔每个格点的值进行量化处理，例如量化为2bit或4bit，因此，在训练时，就要加入随机噪声来模拟这样的情况。简而言之，对于采用$b$位量化的特征采样结果，会加入一个在$[-\frac{2^b-1}{2}\cdot\frac{1}{2^b},-\frac{2^b}{2}\cdot\frac{1}{2^b}]$均匀分布的随机数，再输入到网络当中。

对特征金字塔的采样分为两部分，对分辨率较大的$G_0$网格，采样坐标相邻四个点的值，使用
"学习到"的权重进行插值，以表征高频信息。而对于分辨率较小的$G_1$网格，直接使用双线性插值。

所谓使用"学习到"的权重进行插值，即将相邻四个网格点的特征+四个表征插值权重的特征拼接起来，作为网络输入的一部分。而四个表征插值权重的特征，由positional encoding得到，本文使用了tranglewave encoding[[Tiny-cuda-nn]]。

由于低分辨率网格已经表征了低频信息，因此高分辨率网格只需要表征高频信息，根据奈奎斯特采样定理，低分辨率网格的分辨率边长最小是原图的(1/8)，这就意味着低分辨率网格上，一个格点可以代表原图上的$8\times8$个像素这么大的区域。因此，在高分辨率网格上，我们需要考虑的问题是，恢复中间空缺的频率段的信息。上采样因子为8,因此需要选择$log_28=3$个核。因此Positional Encoding中，使用的position为将图像分为$8\times8$的小格后，采样点在这个小格中的局部uv坐标。

最终的网络输入分为以下部分：
+ $4C_0$:即$G_0$最近四个格点的特征向量
+ $C_1$:即$G_1$的双线性插值得到的特征向量
+ 12：positional encoding后的结果，为$4\times3$
+ 1：归一化后的需要恢复的Lod层数
## 网络
网络训练是对特征金字塔和MLP一起进行优化，采用L2 Loss。

# 实现
## 压缩
