# 摘要
本文在R3D GS的基础上，使用神经网络进行次表面辐射度预测，并结合了次表面辐射度预测结果和表面BRDF实时渲染出带表面信息的次表面散射结果。
# 方法
## 可重光照的3DGS
本文基于的工作是[[Relightable 3DGS]]，这个文章将3DGS分解为显式的材质参数如albedo、粗糙度、金属度、法线等，然后再应用Disney BRDF进行重光照。
# 渲染流程
本文采用的渲染模型同时考虑了两个方面：表面反射和次表面散射，通过一个次表面系数$sss$来控制，渲染方程如下：
$$
L = sss\cdot L_{out}+(1-sss)\cdot(f_{specular}+f_{diffuse})\cdot \bar{L}_{in}\cdot(n\cdot\omega_{in})
$$
pipeline如下：
![](论文/3DGS/pics/2.png)
先由Gaussian光栅化得到GBuffer，再在延迟渲染流程中应用上述方程得到渲染结果。
# 辐照度预测网络设计
一个BSSRDF如下所示：
![](论文/3DGS/pics/1.png)
为了渲染表面反射结果，需要Incident Light，因此设计的网络如下，除了预测出射辐射度之外，还预测了在中心点处的入射光。
![](论文/3DGS/pics/3.png)
其中$\mu$和$\Sigma$是高斯的中心点和协方差矩阵，$v$是球谐函数表达的可见项。另外，这个网络预测的是高斯球所覆盖的小区域的辐射度而非一个准确空间位置的辐射度。同时作者认为，同时预测出射和入射辐射度有利于网络去学习二者之间的联系。
# 实验
## 数据集和网络训练
本文准备了两个OLAT(one light at a time)数据集：
+ 合成数据集：使用Blender和Cycles渲染引擎对五个不同物体渲染了11200张训练数据和22400张测试数据
+ 真实数据集：使用半球上布置的相机拍摄，得到了25000张图像均分到训练集和测试集中，并丢弃了10%不太好的数据。
网络使用三层MLP，激活函数是Leaky-ReLU，Incident Lighting输出端使用一个32个神经元、激活函数为Leaky-ReLU的层+一个ReLU输出层，SSS输出端最后一层使用的是Sigmoid输出层。

## 定性对比结果
+ 在表面反射细节方面，对比了R3DGS，本文方法由于延迟渲染，能够更精细地处理表面反射细节，并且R3DGS不能对次表面散射物体进行重光照
![](论文/3DGS/pics/4.png)
+ 在实时神经渲染方面，对比了KiloOSF，本文方法能在较短训练时间内达到artifect更少的效果
![](论文/3DGS/pics/5.png)
## 定量对比结果
本文选取了PSNR、SSIM、LPIPS三个指标来评估渲染结果，对比结果如下表：
![](论文/3DGS/pics/6.png)
可以看到在质量指标、训练时间和性能指标上，本文方法均优于KiloOSF。

## 其他
本文方法还提供了可编辑表面材质属性(这是由于使用的渲染方程)和可应用与环境光(将环境光重新采样成为点光源)的选项

# 局限性
+ 由于采用较为简单的MLP，难以处理非均质材质
+ 更换几何或更换BSSRDF需要重新训练(需烘焙)
+ 由于采用了3DGS，自阴影方面精度不够高
