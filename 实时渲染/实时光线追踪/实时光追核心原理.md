# 实时光追核心原理

## RTX
RTX的突破在于，增加专用硬件结构(RT Core)来用于光线求交运算，大大增加了单位时间追踪的光线数量
图像的最终结果与每个像素点发射的光线数量相关，为了保证速度会造成巨大的噪声，因此实时光追的一个重要的部分是降噪

## 主流降噪方法
+ Sheared filtering series(SF,AAF,FSF,MAAF)
+ offline filtering methods(IPP.BM3D,APR)
+ Deep learning series(CNN,Autoencoder)

## 工业界解决方案:Temporal
### 核心思想
+ 当前帧的前一帧已经完成滤波，且大部分情况下场景连续变化
+ 使用Motion Vector来记录任意一点上一帧大致位置
+ 因此上一帧的信息可以用在这一帧的滤波

### Geometry-Buffer
G-Buffer可以在屏幕空间轻量级地记录一些渲染所需的信息（如世界坐标等）

### Back Projection
要使用上一帧的数据，我们需要确定每一个像素点对应的场景的点在上一帧是哪一个像素点
在G-Buffer中保存其世界坐标，或者保存变换矩阵，做逆变换
做如下推导：
$$
\begin{matrix}
对于屏幕空间上的点s_i,要求s_{i-1}\\
先求得其对应的世界空间坐标点x_i \\
根据运动变换矩阵T有x_{i-1}=T^{-1}x_i\\
根据保存的上一帧变换矩阵\\
s_{i-1}=E_{i-1}P_{i-1}V_{i-1}M_{i-1}x_{i-1}
\end{matrix}
$$

### 结合
通过上述方法得到的两帧数据，可以使用某种结合方法来计算得到这一帧的结果
$$
\begin{matrix}
\overline{C_i}=Filter[\widetilde{C_{i}}]\\
\overline{C_i}=\alpha\overline{C_i}+(1-\alpha)\overline{C_{i-1}}\\
一般\alpha\approx0.1\sim0.2
\end{matrix}
$$
### Temporal方法存在的问题
+ 当切换场景（或者切换镜头）或者场景中的光照发生了巨大变化时
+ 屏幕空间保存的信息存在局限
+ 物体存在遮挡关系时，某一些点对应的上一帧的点可能不是同一个物体的点(disocclution)
+ 在Glossy反射的情况下，反射面不动，而其反射的物体动了,motion vec为0，就会导致反射落后于物体运动

如果强行复用上一帧的错误结果，会发生拖尾(Lagging)